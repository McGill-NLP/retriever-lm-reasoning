{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THglqpGS7s7O",
        "outputId": "c4bf6cbd-1bed-49e0-daaa-c068d5be6c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
      ],
      "metadata": {
        "id": "6RccxU638F6-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "84po1WFA8nBi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Flan-T5 in Target Ranking"
      ],
      "metadata": {
        "id": "g09yWyZVyF-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_instruction = 'Find <extra_id_0>.'\n",
        "samples = [\n",
        "    {\"id\": 1,\n",
        "     \"query\": \"Scientists are studying the quality of the water in the <extra_id_0>.\",\n",
        "     \"facts\": [\"Taking samples of water is used for studying the quality of water.\", \"Scientists go to a lake once a month to take samples of water.\"],\n",
        "     \"targets\": [\"<extra_id_0> lake\", \"<extra_id_0> water\"]},\n",
        "    {\"id\": 2,\n",
        "     \"query\": \"Matter in solid phase has definite shape and <extra_id_0>.\",\n",
        "     \"facts\": [\"Matter in the solid phase has definite shape.\", \"Matter in the solid phase has definite volume.\"],\n",
        "     \"targets\": [\"<extra_id_0> volume\", \"<extra_id_0> shape\", \"<extra_id_0> volume\"]},\n",
        "    {\"id\": 3,\n",
        "     \"query\": \"The <extra_id_0> is opaque.\",\n",
        "     \"facts\": [\"If an object is opaque , then light will not shine through that object.\", \"Opacity is a property of an object and includes ordered values of opaque / translucent / transparent.\", \"The light cannot shine through an object.\"],\n",
        "     \"targets\": ['<extra_id_0> object', '<extra_id_0> opacity']},\n",
        "]"
      ],
      "metadata": {
        "id": "oypmjfhQyKMh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_ex(query, retrieved_passages, tokenizer, instruction=''):\n",
        "    def append_question(q, docs):\n",
        "        return ['{}\\n {} {}'.format(instruction, \" \".join(docs), q[0])]\n",
        "\n",
        "    text_passages = append_question(query, retrieved_passages)\n",
        "    passage_ids, passage_masks = [], []\n",
        "    p = tokenizer.batch_encode_plus(\n",
        "        text_passages,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    passage_ids.append(p['input_ids'][None])\n",
        "    passage_masks.append(p['attention_mask'][None])\n",
        "    passage_ids = torch.cat(passage_ids, dim=0)\n",
        "    passage_masks = torch.cat(passage_masks, dim=0).bool()\n",
        "    passage_ids, passage_masks = passage_ids.squeeze(1), passage_masks.squeeze(1)\n",
        "    return passage_ids, passage_masks, text_passages\n",
        "\n",
        "def encode_target(targets, tokenizer):\n",
        "    target = tokenizer.batch_encode_plus(\n",
        "        targets,\n",
        "        max_length=200,\n",
        "        padding=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    target_ids = target[\"input_ids\"]\n",
        "    target_mask = target[\"attention_mask\"].bool()\n",
        "    target_ids = target_ids.masked_fill(~target_mask, -100)\n",
        "    return target_ids, target_mask"
      ],
      "metadata": {
        "id": "_dIGckCj12kD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_ranking(sample, flan, tokenizer):\n",
        "    targets = sample[\"targets\"]\n",
        "    alt_num = len(targets)\n",
        "    target_losses = torch.zeros(alt_num)\n",
        "    query = sample[\"query\"]\n",
        "\n",
        "    context_ids, context_mask, new_q = encode_ex([query], sample[\"facts\"], tokenizer, instruction=lm_instruction)\n",
        "    label_ids, _ = encode_target(targets, tokenizer)\n",
        "    for alt_i in range(alt_num):\n",
        "        labels_output = flan(input_ids=context_ids.to(device), attention_mask=context_mask.to(device), labels=label_ids[alt_i].unsqueeze(0).to(device))\n",
        "        target_losses[alt_i] = labels_output[0]\n",
        "    predicted_alt = torch.argmin(target_losses)\n",
        "    return new_q, predicted_alt, target_losses"
      ],
      "metadata": {
        "id": "Jbvuk0eN1X08"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in samples:\n",
        "    new_q, pred, loss = target_ranking(sample, model, tokenizer)\n",
        "    print(\"{} {})\\tquery: {}\\n\\ttargets: {}\\n\\t\\tpred:\\t{} (loss: {}),\\n\\t\\tanswer:\\t{} (loss: {})\\n\".format(\"+\" if pred == 0 else \"-\", sample[\"id\"], new_q, sample[\"targets\"], sample[\"targets\"][pred], loss[pred], sample[\"targets\"][0], loss[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sWfkEut3m6v",
        "outputId": "9742c656-0f94-4565-e3b6-c9106607c2d9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ 1)\tquery: ['Find <extra_id_0>.\\n Taking samples of water is used for studying the quality of water. Scientists go to a lake once a month to take samples of water. Scientists are studying the quality of the water in the <extra_id_0>.']\n",
            "\ttargets: ['<extra_id_0> lake', '<extra_id_0> water']\n",
            "\t\tpred:\t<extra_id_0> lake (loss: 16.30898094177246),\n",
            "\t\tanswer:\t<extra_id_0> lake (loss: 16.30898094177246)\n",
            "\n",
            "- 2)\tquery: ['Find <extra_id_0>.\\n Matter in the solid phase has definite shape. Matter in the solid phase has definite volume. Matter in solid phase has definite shape and <extra_id_0>.']\n",
            "\ttargets: ['<extra_id_0> volume', '<extra_id_0> shape', '<extra_id_0> volume']\n",
            "\t\tpred:\t<extra_id_0> shape (loss: 17.38692283630371),\n",
            "\t\tanswer:\t<extra_id_0> volume (loss: 18.05997657775879)\n",
            "\n",
            "- 3)\tquery: ['Find <extra_id_0>.\\n If an object is opaque , then light will not shine through that object. Opacity is a property of an object and includes ordered values of opaque / translucent / transparent. The light cannot shine through an object. The <extra_id_0> is opaque.']\n",
            "\ttargets: ['<extra_id_0> object', '<extra_id_0> opacity']\n",
            "\t\tpred:\t<extra_id_0> opacity (loss: 7.888247013092041),\n",
            "\t\tanswer:\t<extra_id_0> object (loss: 15.405448913574219)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
