{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THglqpGS7s7O",
        "outputId": "c4bf6cbd-1bed-49e0-daaa-c068d5be6c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
      ],
      "metadata": {
        "id": "6RccxU638F6-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "84po1WFA8nBi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Flan-T5 in Target Ranking"
      ],
      "metadata": {
        "id": "g09yWyZVyF-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_instruction = 'Find <extra_id_0>.'\n",
        "samples = [\n",
        "    {\"id\": 1,\n",
        "     \"query\": \"Scientists are studying the quality of the water in the <extra_id_0>.\",\n",
        "     \"facts\": [\"Taking samples of water is used for studying the quality of water.\", \"Scientists go to a lake once a month to take samples of water.\"],\n",
        "     \"targets\": [\"<extra_id_0> lake\", \"<extra_id_0> water\"]},\n",
        "    {\"id\": 2,\n",
        "     \"query\": \"Matter in solid phase has definite shape and <extra_id_0>.\",\n",
        "     \"facts\": [\"Matter in the solid phase has definite shape.\", \"Matter in the solid phase has definite volume.\"],\n",
        "     \"targets\": [\"<extra_id_0> volume\", \"<extra_id_0> shape\", \"<extra_id_0> volume\"]},\n",
        "    {\"id\": 3,\n",
        "     \"query\": \"The <extra_id_0> is opaque.\",\n",
        "     \"facts\": [\"If an object is opaque , then light will not shine through that object.\", \"Opacity is a property of an object and includes ordered values of opaque / translucent / transparent.\", \"The light cannot shine through an object.\"],\n",
        "     \"targets\": ['<extra_id_0> object', '<extra_id_0> opacity']},\n",
        "]"
      ],
      "metadata": {
        "id": "oypmjfhQyKMh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_ex(query, retrieved_passages, tokenizer, instruction=''):\n",
        "    def append_question(q, docs):\n",
        "        return ['{}\\n {} {}'.format(instruction, \" \".join(docs), q[0])]\n",
        "\n",
        "    text_passages = append_question(query, retrieved_passages)\n",
        "    passage_ids, passage_masks = [], []\n",
        "    p = tokenizer.batch_encode_plus(\n",
        "        text_passages,\n",
        "        max_length=512,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    passage_ids.append(p['input_ids'][None])\n",
        "    passage_masks.append(p['attention_mask'][None])\n",
        "    passage_ids = torch.cat(passage_ids, dim=0)\n",
        "    passage_masks = torch.cat(passage_masks, dim=0).bool()\n",
        "    passage_ids, passage_masks = passage_ids.squeeze(1), passage_masks.squeeze(1)\n",
        "    return passage_ids, passage_masks, text_passages\n",
        "\n",
        "def encode_target(targets, tokenizer):\n",
        "    target = tokenizer.batch_encode_plus(\n",
        "        targets,\n",
        "        max_length=200,\n",
        "        padding=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    target_ids = target[\"input_ids\"]\n",
        "    target_mask = target[\"attention_mask\"].bool()\n",
        "    target_ids = target_ids.masked_fill(~target_mask, -100)\n",
        "    return target_ids, target_mask"
      ],
      "metadata": {
        "id": "_dIGckCj12kD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_ranking(sample, flan, tokenizer):\n",
        "    targets = sample[\"targets\"]\n",
        "    alt_num = len(targets)\n",
        "    target_losses = torch.zeros(alt_num)\n",
        "    query = sample[\"query\"]\n",
        "\n",
        "    context_ids, context_mask, new_q = encode_ex([query], sample[\"facts\"], tokenizer, instruction=lm_instruction)\n",
        "    label_ids, _ = encode_target(targets, tokenizer)\n",
        "    for alt_i in range(alt_num):\n",
        "        labels_output = flan(input_ids=context_ids.to(device), attention_mask=context_mask.to(device), labels=label_ids[alt_i].unsqueeze(0).to(device))\n",
        "        target_losses[alt_i] = labels_output[0]\n",
        "    predicted_alt = torch.argmin(target_losses)\n",
        "    return new_q, predicted_alt, target_losses"
      ],
      "metadata": {
        "id": "Jbvuk0eN1X08"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in samples:\n",
        "    new_q, pred, loss = target_ranking(sample, model, tokenizer)\n",
        "    print(\"{} {})\\tquery: {}\\n\\ttargets: {}\\n\\t\\tpred:\\t{} (loss: {}),\\n\\t\\tanswer:\\t{} (loss: {})\\n\".format(\"+\" if pred == 0 else \"-\", sample[\"id\"], new_q, sample[\"targets\"], sample[\"targets\"][pred], loss[pred], sample[\"targets\"][0], loss[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sWfkEut3m6v",
        "outputId": "9742c656-0f94-4565-e3b6-c9106607c2d9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ 1)\tquery: ['Find <extra_id_0>.\\n Taking samples of water is used for studying the quality of water. Scientists go to a lake once a month to take samples of water. Scientists are studying the quality of the water in the <extra_id_0>.']\n",
            "\ttargets: ['<extra_id_0> lake', '<extra_id_0> water']\n",
            "\t\tpred:\t<extra_id_0> lake (loss: 16.30898094177246),\n",
            "\t\tanswer:\t<extra_id_0> lake (loss: 16.30898094177246)\n",
            "\n",
            "- 2)\tquery: ['Find <extra_id_0>.\\n Matter in the solid phase has definite shape. Matter in the solid phase has definite volume. Matter in solid phase has definite shape and <extra_id_0>.']\n",
            "\ttargets: ['<extra_id_0> volume', '<extra_id_0> shape', '<extra_id_0> volume']\n",
            "\t\tpred:\t<extra_id_0> shape (loss: 17.38692283630371),\n",
            "\t\tanswer:\t<extra_id_0> volume (loss: 18.05997657775879)\n",
            "\n",
            "- 3)\tquery: ['Find <extra_id_0>.\\n If an object is opaque , then light will not shine through that object. Opacity is a property of an object and includes ordered values of opaque / translucent / transparent. The light cannot shine through an object. The <extra_id_0> is opaque.']\n",
            "\ttargets: ['<extra_id_0> object', '<extra_id_0> opacity']\n",
            "\t\tpred:\t<extra_id_0> opacity (loss: 7.888247013092041),\n",
            "\t\tanswer:\t<extra_id_0> object (loss: 15.405448913574219)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Flan-T5's loss [old]"
      ],
      "metadata": {
        "id": "9AKVwEE8x4jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Parishad is studying at <extra_id_0> in Canada.\"\n",
        "inputs = tokenizer(query, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "R0fWyt-j8KNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which of these human activities in a forest has a positive effect on the ecosystem?\\nAnswer: Planting new trees where old ones were cut down\\n\\nQuestion: Which is the best plan to make the fossil fuel supply last longer?\\nAnswer: reduce electricity use\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n[1] «Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?»\\n[2] «As the distance of a location from the north pole becomes smaller / closer , the amount of daylight received by that location will increase during the summer.»\\n[3] «When the season changes , the amount of daylight will change.»\\n[4] «If a place is in summer, then it will have the most sunlight.»\\n[5] «Daylight hours means time during which there is daylight.»\\n[6] «If places are receiving the same amount of sunlight , then these places will have similar seasonal weather pattern.»\\n\\nQuestion: Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?\\n\\nRationale: Let\\'s think step by step. Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?\\n\\nAnswer:'\n",
        "inputs2 = tokenizer(query2, return_tensors=\"pt\").to(device)\n",
        "outputs2 = model.generate(**inputs2, max_new_tokens=150)\n",
        "print(tokenizer.batch_decode(outputs2, skip_special_tokens=True))\n",
        "print(inputs2.input_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YL_4yVJ2Rcp",
        "outputId": "30447cc4-1d0e-43d8-efa4-8f6166c9050d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[1] ---']\n",
            "torch.Size([1, 401])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = 'Answer questions with short factoid answers.\\n\\n---\\n\\nQuestion: Which of these human activities in a forest has a positive effect on the ecosystem?\\nAnswer: Planting new trees where old ones were cut down\\n\\nQuestion: Which is the best plan to make the fossil fuel supply last longer?\\nAnswer: reduce electricity use\\n\\n---\\n\\nFollow the following format.\\n\\nContext:\\n${sources that may contain relevant content}\\n\\nQuestion: ${the question to be answered}\\n\\nRationale: Let\\'s think step by step. ${a step-by-step deduction that identifies the correct response, which will be provided below}\\n\\nAnswer: ${a short factoid answer, often between 1 and 5 words}\\n\\n---\\n\\nContext:\\n- «Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?»\\n- «As the distance of a location from the north pole becomes smaller / closer , the amount of daylight received by that location will increase during the summer.»\\n- «When the season changes , the amount of daylight will change.»\\n- «If a place is in summer, then it will have the most sunlight.»\\n- «Daylight hours means time during which there is daylight.»\\n «If places are receiving the same amount of sunlight , then these places will have similar seasonal weather pattern.»\\n\\nQuestion: Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?\\n\\nRationale: Let\\'s think step by step. Melinda learned that days in some seasons have more daylight hours than in other seasons. Which season receives the most hours of sunlight in the Northern Hemisphere?\\n\\nAnswer:'\n",
        "inputs2 = tokenizer(query2, return_tensors=\"pt\").to(device)\n",
        "outputs2 = model.generate(**inputs2, max_new_tokens=150)\n",
        "print(tokenizer.batch_decode(outputs2, skip_special_tokens=True))\n",
        "print(inputs2.input_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_WmHNPpMz0H",
        "outputId": "716e2a12-3769-45da-86bf-735c362f52b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As the distance of a location from the north pole becomes smaller / closer, the amount of daylight received by that location will increase during the summer.» ---']\n",
            "torch.Size([1, 395])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next token prediction\n",
        "outputs = model.generate(**inputs, max_length=3)\n",
        "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "qeXrEE7H_zCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e31545-d8ee-48d9-aeb3-0e03c7f45d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Parishad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# target ranking\n",
        "options = [\"<extra_id_0> cheese\", \"<extra_id_0> Harvard University\", \"<extra_id_0> University of Montreal\"]\n",
        "options_loss = torch.zeros(len(options))\n",
        "for i, option in enumerate(options):\n",
        "  _input = tokenizer(option, return_tensors=\"pt\").to(device)\n",
        "  loss = model(**inputs, labels=_input.input_ids)[0].item()\n",
        "  options_loss[i] = loss\n",
        "\n",
        "print('Query:', query)\n",
        "print('Best option:', options[torch.argmin(options_loss)])\n",
        "print('Losses:', list(zip(options, options_loss.tolist())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L_7Pqzf98cy",
        "outputId": "ba8ecf94-5dd6-4b21-e4d4-1dc05b96e0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Parishad is studying at <extra_id_0> in Canada.\n",
            "Best option: <extra_id_0> University of Montreal\n",
            "Losses: [('<extra_id_0> cheese', 18.1092472076416), ('<extra_id_0> Harvard University', 12.804937362670898), ('<extra_id_0> University of Montreal', 10.592082977294922)]\n"
          ]
        }
      ]
    }
  ]
}